{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25dfbacd",
   "metadata": {},
   "source": [
    "### **1. Load Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337a78a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.util import add_cyclic_point\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e100c2b",
   "metadata": {},
   "source": [
    "### **2. Pre-setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e82730",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", message=\"facecolor will have no effect as it has been defined as \\\"never\\\".\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"This figure includes Axes that are not compatible with tight_layout\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"Glyph 8322\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"Warning: 'partition' will ignore the 'mask' of the MaskedArray.\")\n",
    "\n",
    "plt.rcParams[\"font.family\"] = [\"DejaVu Sans\", \"Arial\"]\n",
    "plt.rcParams[\"font.size\"] = 12  # 基础字体大小\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False  # 解决负号显示问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab65840",
   "metadata": {},
   "source": [
    "### **3. Define datetime and files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc0981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_date_str = \"2020-08-15\"\n",
    "target_date = np.datetime64(target_date_str)\n",
    "target_time = np.datetime64(f\"{target_date_str}T13:30\")\n",
    "\n",
    "ct_file = f\"/data3/interns/NRT_CO2_Emission_Map_Project/MingjuanZhang_work/CarbonTracker/xCO2_1330LST_global/CT2022.xCO2_1330_glb3x2_{target_date_str}.nc\"\n",
    "cams_file = f\"/data3/interns/NRT_CO2_Emission_Map_Project/MingjuanZhang_work/CAMS/cams_data/cams73_latest_co2_col_surface_inst_202008.nc\"\n",
    "ml_file = f\"/data3/interns/NRT_CO2_Emission_Map_Project/ML_XCO2/XCO2_prediction_full/monthly_xco2_full_2020_08.npy\"\n",
    "\n",
    "for file_path in [ct_file, cams_file, ml_file]:\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Warning: File does not exist -> {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cefd663",
   "metadata": {},
   "source": [
    "### **4. Read Data (Daily)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0966a91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 CarbonTracker\n",
    "ds_ct = xr.open_dataset(ct_file)\n",
    "ct_lon_name = 'lon' if 'lon' in ds_ct.variables else 'longitude'\n",
    "ct_lat_name = 'lat' if 'lat' in ds_ct.variables else 'latitude'\n",
    "ct_lon = ds_ct[ct_lon_name].values\n",
    "ct_lat = ds_ct[ct_lat_name].values\n",
    "ct_xco2 = ds_ct['xco2'].isel(time=0).values\n",
    "ct_xco2, ct_lon = add_cyclic_point(ct_xco2, coord=ct_lon)\n",
    "ds_ct.close()\n",
    "\n",
    "# 2.2 CAMS\n",
    "ds_cams = xr.open_dataset(cams_file)\n",
    "cams_lon_name = 'lon' if 'lon' in ds_cams.variables else 'longitude'\n",
    "cams_lat_name = 'lat' if 'lat' in ds_cams.variables else 'latitude'\n",
    "cams_lon = ds_cams[cams_lon_name].values\n",
    "cams_lat = ds_cams[cams_lat_name].values\n",
    "cams_time = ds_cams['time'].values\n",
    "june1_mask = (cams_time >= target_date) & (cams_time < target_date + np.timedelta64(1, 'D'))\n",
    "if np.any(june1_mask):\n",
    "    cams_june1 = ds_cams['XCO2'].isel(time=june1_mask)\n",
    "    closest_idx = np.argmin(np.abs(cams_june1['time'].values - target_time))\n",
    "    cams_xco2_raw = cams_june1.isel(time=closest_idx).values\n",
    "else:\n",
    "    print(f\"Warning: No data found for {target_date_str} in CAMS, using first time step\")\n",
    "    cams_xco2_raw = ds_cams['XCO2'].isel(time=0).values\n",
    "cams_xco2 = cams_xco2_raw * 1000000\n",
    "cams_xco2, cams_lon = add_cyclic_point(cams_xco2, coord=cams_lon)\n",
    "ds_cams.close()\n",
    "\n",
    "# 2.3 Ours\n",
    "ml_struct = np.load(ml_file)\n",
    "if 'xco2_pred' in ml_struct.dtype.names:\n",
    "    ml_xco2_pred = ml_struct['xco2_pred']\n",
    "    ml_lon = ml_struct['lon']\n",
    "    ml_lat = ml_struct['lat']\n",
    "else:\n",
    "    raise ValueError(\"'xco2_pred' field not found in ML data file, please check data structure.\")\n",
    "unique_lon = np.unique(ml_lon)\n",
    "unique_lat = np.unique(ml_lat)\n",
    "ml_grid = np.full((len(unique_lat), len(unique_lon)), np.nan)\n",
    "lon_indices = np.searchsorted(unique_lon, ml_lon)\n",
    "lat_indices = np.searchsorted(unique_lat, ml_lat)\n",
    "valid = (lon_indices < len(unique_lon)) & (lat_indices < len(unique_lat)) & ~np.isnan(ml_xco2_pred)\n",
    "ml_grid[lat_indices[valid], lon_indices[valid]] = ml_xco2_pred[valid]\n",
    "ml_grid, unique_lon = add_cyclic_point(ml_grid, coord=unique_lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76df529",
   "metadata": {},
   "source": [
    "### **5. Matching the final**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552e2e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_struct = np.load(ml_file, allow_pickle=True)\n",
    "\n",
    "required_fields = {\"xco2_pred\", \"lon\", \"lat\"}\n",
    "if not required_fields.issubset(set(ml_struct.dtype.names or [])):\n",
    "    raise ValueError(f\"ML file missing fields. Need {required_fields}, got {ml_struct.dtype.names}\")\n",
    "\n",
    "ml_xco2_pred_all = ml_struct[\"xco2_pred\"]\n",
    "ml_lon_all = ml_struct[\"lon\"]\n",
    "ml_lat_all = ml_struct[\"lat\"]\n",
    "\n",
    "time_field_candidates = [\"time\", \"datetime\", \"date\", \"timestamp\", \"Time\", \"DATE\", \"Datetime\"]\n",
    "time_field = next((f for f in time_field_candidates if f in (ml_struct.dtype.names or [])), None)\n",
    "\n",
    "if time_field is None:\n",
    "    raise ValueError(\n",
    "        f\"Your ML .npy has no time field ({time_field_candidates}). \"\n",
    "        \"So I cannot select a specific day/time. Please check the file structure.\"\n",
    "    )\n",
    "\n",
    "ml_time = pd.to_datetime(ml_struct[time_field], errors=\"coerce\")\n",
    "ml_time64 = ml_time.to_numpy(dtype=\"datetime64[ns]\")\n",
    "\n",
    "day_mask = (ml_time64 >= target_date) & (ml_time64 < target_date + np.timedelta64(1, \"D\"))\n",
    "if not np.any(day_mask):\n",
    "    raise ValueError(f\"No ML data found on {target_date_str} in field '{time_field}'.\")\n",
    "\n",
    "day_times = ml_time64[day_mask]\n",
    "closest_i = np.argmin(np.abs(day_times - target_time))\n",
    "selected_time = day_times[closest_i]\n",
    "\n",
    "time_mask = (ml_time64 == selected_time)\n",
    "ml_lon = ml_lon_all[time_mask]\n",
    "ml_lat = ml_lat_all[time_mask]\n",
    "ml_xco2_pred = ml_xco2_pred_all[time_mask]\n",
    "\n",
    "df_ml = pd.DataFrame({\"lon\": ml_lon, \"lat\": ml_lat, \"xco2_pred\": ml_xco2_pred})\n",
    "df_ml = df_ml.dropna(subset=[\"lon\", \"lat\", \"xco2_pred\"])\n",
    "df_ml = df_ml.groupby([\"lat\", \"lon\"], as_index=False)[\"xco2_pred\"].mean()\n",
    "\n",
    "ml_lon = df_ml[\"lon\"].to_numpy()\n",
    "ml_lat = df_ml[\"lat\"].to_numpy()\n",
    "ml_xco2_pred = df_ml[\"xco2_pred\"].to_numpy()\n",
    "\n",
    "print(f\"[ML] Using time = {pd.Timestamp(selected_time).isoformat()} (closest to {pd.Timestamp(target_time).isoformat()})\")\n",
    "print(f\"[ML] Points used = {len(ml_xco2_pred)}\")\n",
    "\n",
    "unique_lon = np.unique(ml_lon)\n",
    "unique_lat = np.unique(ml_lat)\n",
    "\n",
    "ml_grid = np.full((len(unique_lat), len(unique_lon)), np.nan)\n",
    "lon_indices = np.searchsorted(unique_lon, ml_lon)\n",
    "lat_indices = np.searchsorted(unique_lat, ml_lat)\n",
    "\n",
    "valid = (\n",
    "    (lon_indices >= 0) & (lon_indices < len(unique_lon)) &\n",
    "    (lat_indices >= 0) & (lat_indices < len(unique_lat)) &\n",
    "    ~np.isnan(ml_xco2_pred)\n",
    ")\n",
    "ml_grid[lat_indices[valid], lon_indices[valid]] = ml_xco2_pred[valid]\n",
    "\n",
    "ml_grid, unique_lon = add_cyclic_point(ml_grid, coord=unique_lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27089ad",
   "metadata": {},
   "source": [
    "### **6. Plotting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedb4632",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ct_valid = ct_xco2[~np.isnan(ct_xco2)]\n",
    "cams_valid = cams_xco2[~np.isnan(cams_xco2)]\n",
    "ml_valid = ml_grid[~np.isnan(ml_grid)]\n",
    "all_data = np.concatenate([ct_valid, cams_valid, ml_valid])\n",
    "vmin = np.percentile(all_data, 2.5)\n",
    "vmax = np.percentile(all_data, 97.5)\n",
    "norm = Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "regions = {\n",
    "    \"Asia\": {\"lon\": [70, 140], \"lat\": [10, 50]},\n",
    "    \"Australia\": {\"lon\": [110, 180], \"lat\": [-50, 0]},\n",
    "    \"North America\": {\"lon\": [-130, -60], \"lat\": [20, 60]},\n",
    "    \"Europe and North Africa\": {\"lon\": [-10, 60], \"lat\": [10, 70]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84accc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"3.2Comparison_xco2_split_figs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "data_labels = [\"CarbonTracker\", \"CAMS\", \"Our Model\"]\n",
    "data_sources = [\n",
    "    (ct_xco2, ct_lon, ct_lat),\n",
    "    (cams_xco2, cams_lon, cams_lat),\n",
    "    (ml_grid, unique_lon, unique_lat)\n",
    "]\n",
    "\n",
    "def safe_name(s):\n",
    "    return (s.replace(\" \", \"_\")\n",
    "             .replace(\"&\", \"and\")\n",
    "             .replace(\"/\", \"_\"))\n",
    "\n",
    "for region_name, bounds in regions.items():\n",
    "    lon_min, lon_max = bounds[\"lon\"]\n",
    "    lat_min, lat_max = bounds[\"lat\"]\n",
    "\n",
    "    for label, (data, lons, lats) in zip(data_labels, data_sources):\n",
    "\n",
    "        fig = plt.figure(figsize=(5, 3.5))\n",
    "        ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "        ax.set_extent([lon_min, lon_max, lat_min, lat_max],\n",
    "                      crs=ccrs.PlateCarree())\n",
    "        ax.add_feature(cfeature.LAND, alpha=0.3)\n",
    "        ax.add_feature(cfeature.COASTLINE, linewidth=1.0)\n",
    "        ax.add_feature(cfeature.BORDERS, linewidth=0.8, color='black')\n",
    "\n",
    "        mesh = ax.pcolormesh(\n",
    "            lons, lats, data,\n",
    "            cmap='Spectral_r', norm=norm, shading='auto'\n",
    "        )\n",
    "\n",
    "        xticks = np.arange(\n",
    "            np.ceil(lon_min / 20) * 20,  \n",
    "            np.floor(lon_max / 20) * 20 + 1e-6, \n",
    "            20\n",
    "        )\n",
    "        ax.set_xticks(xticks, crs=ccrs.PlateCarree())\n",
    "\n",
    "        yticks = np.arange(\n",
    "            np.ceil(lat_min / 20) * 20,\n",
    "            np.floor(lat_max / 20) * 20 + 1e-6,\n",
    "            20\n",
    "        )\n",
    "        ax.set_yticks(yticks, crs=ccrs.PlateCarree())\n",
    "\n",
    "        def format_func(x, pos):\n",
    "            return f\"{x:.0f}\"\n",
    "\n",
    "        ax.xaxis.set_major_formatter(plt.FuncFormatter(format_func))\n",
    "        ax.yaxis.set_major_formatter(plt.FuncFormatter(format_func))\n",
    "        ax.tick_params(axis='both', labelsize=11)\n",
    "\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_edgecolor('black')\n",
    "            spine.set_linewidth(1.5)\n",
    "\n",
    "        fname = f\"xco2_{safe_name(region_name)}_{safe_name(label)}_{target_date_str.replace('-', '')}.png\"\n",
    "        fpath = os.path.join(output_dir, fname)\n",
    "        plt.savefig(fpath, dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "        print(f\"Saved: {fpath}\")\n",
    "\n",
    "fig_cb = plt.figure(figsize=(6, 1.0)) \n",
    "ax_cb = fig_cb.add_axes([0.05, 0.4, 0.9, 0.25])\n",
    "sm = ScalarMappable(norm=norm, cmap='Spectral_r')\n",
    "sm.set_array([])\n",
    "cbar = fig_cb.colorbar(sm, cax=ax_cb, orientation='horizontal')\n",
    "cbar.ax.set_xlabel(r'XCO$\\mathregular{_2}$ (ppm)', fontsize=14)\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "cbar.locator = MaxNLocator(nbins=8)\n",
    "cbar.update_ticks()\n",
    "cb_fname = f\"xco2_colorbar_{target_date_str.replace('-', '')}.png\"\n",
    "cb_fpath = os.path.join(output_dir, cb_fname)\n",
    "plt.savefig(cb_fpath, dpi=300, bbox_inches='tight')\n",
    "plt.close(fig_cb)\n",
    "print(f\"Saved colorbar: {cb_fpath}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_jupyter_env)",
   "language": "python",
   "name": "my_jupyter_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
