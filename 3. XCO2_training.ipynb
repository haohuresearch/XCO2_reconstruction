{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f164dac9-2ac7-443d-bdba-7d04aa32987a",
   "metadata": {},
   "source": [
    "# **1 Global Set-up**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7a0fd6-d590-4466-a825-9c7b77ef2cc1",
   "metadata": {},
   "source": [
    "## **1.1 Define All Variables and folder path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62964675-25ff-4061-a306-dbd46e4786a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = {\n",
    "    \"xco2\": \"/data3/interns/NRT_CO2_Emission_Map_Project/HaoHu_work/XCO2_resample/global_grid_0.1_2019_2025_xco2.nc\",\n",
    "    \"emission\": \"/data3/interns/NRT_CO2_Emission_Map_Project/ML_XCO2/CarbonMonitor0Power_emission_201901_202505.nc\"  \n",
    "}\n",
    "feature_variables = {\n",
    "    \"t2m\": \"/data3/interns/NRT_CO2_Emission_Map_Project/HaoHu_work/ERA5_resample/t2m_daily_0p1deg.nc\",\n",
    "    \"d2m\": \"/data3/interns/NRT_CO2_Emission_Map_Project/HaoHu_work/ERA5_resample/d2m_daily_0p1deg.nc\",\n",
    "    \"u10\": \"/data3/interns/NRT_CO2_Emission_Map_Project/HaoHu_work/ERA5_resample/u10_daily_0p1deg.nc\",\n",
    "    \"v10\": \"/data3/interns/NRT_CO2_Emission_Map_Project/HaoHu_work/ERA5_resample/v10_daily_0p1deg.nc\",\n",
    "    \"msl\": \"/data3/interns/NRT_CO2_Emission_Map_Project/HaoHu_work/ERA5_resample/msl_daily_0p1deg.nc\",\n",
    "    \"sp\": \"/data3/interns/NRT_CO2_Emission_Map_Project/HaoHu_work/ERA5_resample/sp_daily_0p1deg.nc\",\n",
    "    \"skt\": \"/data3/interns/NRT_CO2_Emission_Map_Project/HaoHu_work/ERA5_resample/skt_daily_0p1deg.nc\",\n",
    "    \"tp\": \"/data3/interns/NRT_CO2_Emission_Map_Project/HaoHu_work/ERA5_resample/tp_daily_0p1deg.nc\",\n",
    "    \"e\": \"/data3/interns/NRT_CO2_Emission_Map_Project/HaoHu_work/ERA5_resample/e_daily_0p1deg.nc\",\n",
    "    \"ssr\": \"/data3/interns/NRT_CO2_Emission_Map_Project/HaoHu_work/ERA5_resample/ssr_daily_0p1deg.nc\",\n",
    "    \"str\": \"/data3/interns/NRT_CO2_Emission_Map_Project/HaoHu_work/ERA5_resample/str_daily_0p1deg.nc\",\n",
    "    \"tcw\": \"/data3/interns/NRT_CO2_Emission_Map_Project/HaoHu_work/ERA5_resample/tcw_daily_0p1deg.nc\",\n",
    "    \"blh\": \"/data3/interns/NRT_CO2_Emission_Map_Project/HaoHu_work/ERA5_resample/blh_daily_0p1deg.nc\",\n",
    "    \n",
    "    \"NO2\": \"/data3/interns/NRT_CO2_Emission_Map_Project/HaoHu_work/XCO2_resample/global_grid_0.1_2019_2025_NO2.nc\",\n",
    "    \"is_weekend\": \"/data3/interns/NRT_CO2_Emission_Map_Project/HaoHu_work/XCO2_resample/global_grid_0.1_2019_2025_weekday_weekend.nc\",\n",
    "    \"population\": \"/data3/interns/NRT_CO2_Emission_Map_Project/MingjuanZhang_work/Population_global_0.1degree_2019_2025_ns.nc\",\n",
    "    \"elevation\": \"/data3/interns/NRT_CO2_Emission_Map_Project/MingjuanZhang_work/SRTM_elevation_global_0.1degree_2019_2025_ns.nc\",\n",
    "    \"landuse\": \"/data3/interns/NRT_CO2_Emission_Map_Project/MingjuanZhang_work/Landuse_global_0.1degree_2019_2025_ns.nc\",\n",
    "    \"aspect\": \"/data3/interns/NRT_CO2_Emission_Map_Project/MingjuanZhang_work/SRTM_aspect_global_0.1degree_2019_2025_ns.nc\",\n",
    "    \"ndvi\": \"/data3/interns/NRT_CO2_Emission_Map_Project/MingjuanZhang_work/NDVI_global_0.1degree_2019_2025_ns.nc\",\n",
    "    \"gpp\": \"/data3/interns/NRT_CO2_Emission_Map_Project/MingjuanZhang_work/GPP_global_0.1degree_2019_2025_ns.nc\",\n",
    "    \"lai\": \"/data3/interns/NRT_CO2_Emission_Map_Project/MingjuanZhang_work/LAI_global_0.1degree_2019_2025_ns.nc\",\n",
    "    \"ntl\": \"/data3/interns/NRT_CO2_Emission_Map_Project/MingjuanZhang_work/VIIRS_NTL_global_0.1degree_2019_2025_ns.nc\",\n",
    "    \"evi\": \"/data3/interns/NRT_CO2_Emission_Map_Project/MingjuanZhang_work/EVI_global_0.1degree_2019_2025_ns.nc\",\n",
    "    \"slope\": \"/data3/interns/NRT_CO2_Emission_Map_Project/MingjuanZhang_work/SRTM_slope_global_0.1degree_2019_2025_ns.nc\",\n",
    "    \"odiac\": \"/data3/interns/NRT_CO2_Emission_Map_Project/HaoHu_work/odiac_interp_2019_2025.nc\",\n",
    "    \"CO2_fire\": \"/data3/interns/NRT_CO2_Emission_Map_Project/PinyiLu_work/GFAS_resample/GFAS_resample_final.nc\",\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3850223b-1718-404d-8e7b-92f6aba07f2e",
   "metadata": {},
   "source": [
    "## **1.2 Load all modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6041a9d0-d2bf-4f34-95f6-9fdefb21ccc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from sklearn.model_selection import GroupKFold, GridSearchCV\n",
    "from xgboost import XGBRegressor, callback \n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error  \n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "import shap\n",
    "\n",
    "import matplotlib.collections as mcoll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45218b9-f929-4be0-af5d-f842eb05eddf",
   "metadata": {},
   "source": [
    "# **2 Model Training and Validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1a0629",
   "metadata": {},
   "source": [
    "## **2.1 Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d359610",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"../xco2_nonnan_processed.npy\", allow_pickle=True)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892f83f7",
   "metadata": {},
   "source": [
    "## **2.2 Split spacetime block to training and test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7f4fc4-527b-4b2b-aefb-7b2597f7d384",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"lat_bin\"] = ((df[\"lat\"] + 90) // 10).astype(int)\n",
    "df[\"lon_bin\"] = ((df[\"lon\"] + 180) // 10).astype(int)\n",
    "\n",
    "df[\"time_bin\"] = (\n",
    "    pd.to_datetime(\n",
    "        df[[\"year\", \"month\"]].assign(day=1)\n",
    "    )\n",
    "    .dt.to_period(\"M\")               \n",
    "    .astype(str)     \n",
    ")\n",
    "\n",
    "df[\"spacetime_block\"] = (\n",
    "      df[\"lat_bin\"].astype(str) + \"_\"+ df[\"lon_bin\"].astype(str) + \"_\"+ df[\"time_bin\"]\n",
    "      )\n",
    "\n",
    "blocks = df[\"spacetime_block\"].unique()\n",
    "train_blocks, test_blocks = train_test_split(\n",
    "    blocks, test_size=0.20, random_state=42\n",
    ")\n",
    "\n",
    "df[\"split\"] = df[\"spacetime_block\"].isin(test_blocks)\\\n",
    "               .map({True: \"test\", False: \"trainval\"})\n",
    "\n",
    "df_trainval = df[df[\"split\"] == \"trainval\"].copy()\n",
    "df_test     = df[df[\"split\"] == \"test\"].copy()\n",
    "\n",
    "print(\"Total number of blocks: \", len(blocks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a6d2d0-e382-4d78-956d-0f5928176b0e",
   "metadata": {},
   "source": [
    "## **2.3 Grid-search best models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3456f6-b846-459c-9f8a-000ebc115423",
   "metadata": {},
   "source": [
    "### 2.3.1 Define grid params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e3e2f4-ff69-47b0-8759-173cecb6b230",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators':         [300],\n",
    "    'max_depth':            [10],\n",
    "    'learning_rate':        [0.1],\n",
    "    'gamma' :               [0.1],\n",
    "    'min_child_weight':     [2],\n",
    "    'subsample':            [0.9],\n",
    "    'colsample_bytree':     [0.9],\n",
    "    'reg_alpha':            [0.01],\n",
    "    'reg_lambda':           [0.01],\n",
    "}\n",
    "\n",
    "params = {k: (v[0] if isinstance(v, (list, tuple, np.ndarray)) else v)\n",
    "          for k, v in param_grid.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7829a2a-261a-43d9-b614-a6d76f50ceeb",
   "metadata": {},
   "source": [
    "### 2.3.2 Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fad2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in df.columns if col not in [\"lat\", \"lon\", \"xco2\", \"time\", \"split\", \"time_bin\", \"lat_bin\", \"lon_bin\", \"spacetime_block\",\"month\", \"emission\"]]\n",
    "print(features)\n",
    "X = df_trainval[features]\n",
    "y = df_trainval[\"xco2\"]\n",
    "groups = df_trainval[\"spacetime_block\"]\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "xgb_model = XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\",\n",
    "    device=\"cuda\", \n",
    "    **params \n",
    ")\n",
    "\n",
    "best_model = xgb_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163ccd95",
   "metadata": {},
   "source": [
    "### 2.3.3 Cross-validation for trainning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8a6c7f-5404-4392-ae4a-8ba4ec654de4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scoring = {\n",
    "    \"RMSE\": \"neg_root_mean_squared_error\",\n",
    "    \"R2\":   \"r2\"\n",
    "}\n",
    "\n",
    "splits = list(gkf.split(X, y, groups=groups))\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=splits,\n",
    "    scoring=scoring,\n",
    "    refit=\"RMSE\",    \n",
    "    return_train_score=True,\n",
    "    verbose=2,\n",
    "    n_jobs=1\n",
    ")\n",
    "X = X.apply(pd.to_numeric, errors='coerce')\n",
    "y = y.apply(pd.to_numeric, errors='coerce')\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "best_idx      = grid_search.best_index_\n",
    "\n",
    "mean_test_rmse = -grid_search.cv_results_[\"mean_test_RMSE\"][best_idx]\n",
    "mean_test_r2   =     grid_search.cv_results_[\"mean_test_R2\"][best_idx]\n",
    "\n",
    "std_test_rmse  =  grid_search.cv_results_[\"std_test_RMSE\"][best_idx]\n",
    "std_test_r2    =  grid_search.cv_results_[\"std_test_R2\"][best_idx]\n",
    "\n",
    "print(f\"✅ The Best params：{grid_search.best_params_}\")\n",
    "print(f\"✅ CV mean RMSE：{mean_test_rmse:.4f}，sd：{std_test_rmse:.4f}\")\n",
    "print(f\"✅ CV mean R²：{mean_test_r2:.4f}，sd：{std_test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc80439",
   "metadata": {},
   "source": [
    "### 2.3.4 Prepare 5-CV dataset saving -> oof_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f05cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_est = best_model \n",
    "\n",
    "n = len(y)\n",
    "oof_pred = np.full(n, np.nan, dtype=float)\n",
    "fold_ids = np.full(n, -1, dtype=int)\n",
    "\n",
    "splits = list(gkf.split(X, y, groups=groups))\n",
    "\n",
    "for k, (tr_idx, va_idx) in enumerate(splits):\n",
    "    est = clone(base_est)\n",
    "    est.fit(X.iloc[tr_idx], y.iloc[tr_idx])\n",
    "    pred = est.predict(X.iloc[va_idx])\n",
    "    oof_pred[va_idx] = pred\n",
    "    fold_ids[va_idx] = k\n",
    "\n",
    "keep_cols = [c for c in [\"lat\", \"lon\"] if c in df.columns]\n",
    "\n",
    "oof_df = pd.DataFrame({\n",
    "    \"y_true\": y.values,\n",
    "    \"y_pred\": oof_pred,\n",
    "    \"fold\":  fold_ids\n",
    "}, index=y.index).join(df.loc[y.index, keep_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf4c86e-4e6e-487e-9da9-986bdfcc6171",
   "metadata": {},
   "source": [
    "## **2.4 Train the final model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0f948f-958e-46f2-bd76-ebffee975f08",
   "metadata": {},
   "source": [
    "### 2.4.1 Using all the trainval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eb4f29-aed7-4680-b119-5c6c67b01d61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_model.fit(X, y)\n",
    "\n",
    "# best_model.save_model(f\"Trained_xgb_model_full/xgb_model_full_random.json\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87bda85",
   "metadata": {},
   "source": [
    "### 2.4.2 Plot 5-cv scattering plots (train and test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b938610",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=oof_df[\"y_true\"]\n",
    "y_pred_train=oof_df[\"y_pred\"]\n",
    "X_test = df_test[features]\n",
    "y_test = df_test[\"xco2\"]\n",
    "\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "r2_test   = r2_score(y_test, y_pred_test)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "r2_train   = r2_score(y_train, y_pred_train)\n",
    "mae_test   = mean_absolute_error(y_test,  y_pred_test)  \n",
    "mb_test    = np.mean(y_pred_test - y_test)\n",
    "\n",
    "mae_train  = mean_absolute_error(y_train, y_pred_train)       \n",
    "mb_train   = np.mean(y_pred_train - y_train)\n",
    "\n",
    "# ===== Plot Figures=====\n",
    "mpl.rcParams.update({\n",
    "    \"font.size\": 11, \n",
    "    \"axes.linewidth\": 1.0,\n",
    "    \"xtick.direction\": \"in\",\n",
    "    \"ytick.direction\": \"in\",\n",
    "    \"xtick.major.size\": 4,\n",
    "    \"ytick.major.size\": 4,\n",
    "})\n",
    "\n",
    "vmin = np.nanmin([y_train.min(), y_test.min(), y_pred_train.min(), y_pred_test.min()])\n",
    "vmax = np.nanmax([y_train.max(), y_test.max(), y_pred_train.max(), y_pred_test.max()])\n",
    "pad  = 0.02 * (vmax - vmin)\n",
    "lims = (vmin - pad, vmax + pad)\n",
    "\n",
    "def panel(ax, y_true, y_pred, tag, rmse, r2, mae, mb,  gridsize=200, cmap=\"RdYlBu_r\"): \n",
    "    hb = ax.hexbin(\n",
    "        y_true, y_pred,\n",
    "        gridsize=gridsize, extent=[*lims, *lims], cmap=cmap,\n",
    "        mincnt=1, bins='log' \n",
    "    )\n",
    "    ax.plot(lims, lims, ls=\"--\", lw=1.2, color=\"k\")\n",
    "    ax.set_xlim(lims); ax.set_ylim(lims)\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    ax.set_xlabel(\"Observed XCO$_2$ (ppm)\")\n",
    "    ax.set_ylabel(\"Predicted XCO$_2$ (ppm)\")\n",
    "    ax.text(0.02, 0.98, f\"({tag})\", transform=ax.transAxes, va=\"top\", ha=\"left\", fontsize=13, fontweight=\"bold\")\n",
    "    ax.text(0.4, 0.3,\n",
    "            f\"RMSE = {rmse:.2f} ppm\\n\"\n",
    "            f\"MAE = {mae:.2f} ppm\\n\"\n",
    "            f\"MB = {mb:+.2f} ppm\\n\"\n",
    "            r\"$R^2$ = \" + f\"{r2:.2f}\",\n",
    "            transform=ax.transAxes, va=\"top\", ha=\"left\",\n",
    "            bbox=dict(boxstyle=\"round,pad=0.25\", fc=\"white\", ec=\"0.6\", lw=0.8))\n",
    "    return hb\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 3.8), sharex=True, sharey=True)\n",
    "hb1 = panel(axes[0], y_train, y_pred_train, \"a\", rmse_train, r2_train, mae_train, mb_train)\n",
    "hb2 = panel(axes[1], y_test,  y_pred_test,  \"b\", rmse_test,  r2_test,  mae_test,  mb_test)\n",
    "\n",
    "fig.tight_layout()\n",
    "cbar = fig.colorbar(hb2, ax=axes.ravel().tolist(), shrink=0.9, pad=0.02)\n",
    "cbar.set_label(\"Point density (log scale)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1dbdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_y_test = np.std(y_test, ddof=1)\n",
    "print(\"STD(y_test) =\", std_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f247c11",
   "metadata": {},
   "source": [
    "### **2.4.3 Plot seasonal (spring, summer, fall, winter) (Train)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c6d0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=oof_df[\"y_true\"]\n",
    "y_pred_test=oof_df[\"y_pred\"]\n",
    "\n",
    "seasons = {\n",
    "    \"DJF (Dec–Feb)\": [12, 1, 2],\n",
    "    \"MAM (Mar–May)\": [3, 4, 5],\n",
    "    \"JJA (Jun–Aug)\": [6, 7, 8],\n",
    "    \"SON (Sep–Nov)\": [9,10,11],\n",
    "}\n",
    "tags = [\"a\", \"b\", \"c\", \"d\"]\n",
    "\n",
    "season_preds = {}\n",
    "for name, months in seasons.items():\n",
    "    mask = df_trainval[\"month\"].isin(months)\n",
    "    if not np.any(mask):\n",
    "        season_preds[name] = None\n",
    "        continue\n",
    "    X_s = df_trainval.loc[mask, features]\n",
    "    y_s = df_trainval.loc[mask, \"xco2\"].values\n",
    "    yhat_s = best_model.predict(X_s)\n",
    "    season_preds[name] = (y_s, yhat_s)\n",
    "\n",
    "all_true = np.concatenate([v[0] for v in season_preds.values() if v is not None])\n",
    "all_pred = np.concatenate([v[1] for v in season_preds.values() if v is not None])\n",
    "vmin = np.nanmin([all_true.min(), all_pred.min()])\n",
    "vmax = np.nanmax([all_true.max(), all_pred.max()])\n",
    "pad  = 0.02 * (vmax - vmin)\n",
    "lims = (vmin - pad, vmax + pad)\n",
    "\n",
    "\n",
    "mpl.rcParams.update({\n",
    "    \"font.size\": 11,\n",
    "    \"axes.linewidth\": 1.0,\n",
    "    \"xtick.direction\": \"in\",\n",
    "    \"ytick.direction\": \"in\",\n",
    "    \"xtick.major.size\": 4,\n",
    "    \"ytick.major.size\": 4,\n",
    "})\n",
    "\n",
    "def panel(ax, y_true, y_pred, tag, title, rmse, mae, mb, r2,\n",
    "          gridsize=200, cmap=\"RdYlBu_r\"):\n",
    "    hb = ax.hexbin(\n",
    "        y_true, y_pred,\n",
    "        gridsize=gridsize, extent=[*lims, *lims], cmap=cmap,\n",
    "        mincnt=1, bins='log'\n",
    "    )\n",
    "    ax.plot(lims, lims, ls=\"--\", lw=1.2, color=\"k\")\n",
    "    ax.set_xlim(lims); ax.set_ylim(lims)\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    ax.set_xlabel(\"Observed XCO$_2$ (ppm)\")\n",
    "    ax.set_ylabel(\"Predicted XCO$_2$ (ppm)\")\n",
    "    ax.text(0.02, 0.98, f\"({tag})\", transform=ax.transAxes,\n",
    "            va=\"top\", ha=\"left\", fontsize=13, fontweight=\"bold\")\n",
    "    ax.text(0.40, 0.3,\n",
    "            f\"RMSE = {rmse:.2f} ppm\\nMAE = {mae:.2f} ppm\\nMB = {mb:+.2f} ppm\\n$R^2$ = {r2:.2f}\",\n",
    "            transform=ax.transAxes, va=\"top\", ha=\"left\",\n",
    "            bbox=dict(boxstyle=\"round,pad=0.25\", fc=\"white\", ec=\"0.6\", lw=0.8))\n",
    "    return hb\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(7.0, 6.5), sharex=True, sharey=True)\n",
    "\n",
    "for ax, (tag, (name, _)) in zip(axes.ravel(), zip(tags, seasons.items())):\n",
    "    pair = season_preds[name]\n",
    "    if pair is None:\n",
    "        ax.text(0.5, 0.5, f\"No data: {name}\", ha=\"center\", va=\"center\", transform=ax.transAxes)\n",
    "        ax.axis(\"off\")\n",
    "        continue\n",
    "\n",
    "    y_s, yhat_s = pair\n",
    "    rmse = np.sqrt(mean_squared_error(y_s, yhat_s))\n",
    "    mae  = mean_absolute_error(y_s, yhat_s)\n",
    "    mb   = np.mean(yhat_s - y_s)\n",
    "    r2   = r2_score(y_s, yhat_s)\n",
    "\n",
    "    panel(ax, y_s, yhat_s, tag, name, rmse, mae, mb, r2, gridsize=80, cmap=\"RdYlBu_r\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23f92d6",
   "metadata": {},
   "source": [
    "### **2.4.4 Plot seasonal (spring, summer, fall, winter) (Test)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9fb624",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = {\n",
    "    \"DJF (Dec–Feb)\": [12, 1, 2],\n",
    "    \"MAM (Mar–May)\": [3, 4, 5],\n",
    "    \"JJA (Jun–Aug)\": [6, 7, 8],\n",
    "    \"SON (Sep–Nov)\": [9,10,11],\n",
    "}\n",
    "tags = [\"a\", \"b\", \"c\", \"d\"]\n",
    "\n",
    "season_preds = {}\n",
    "for name, months in seasons.items():\n",
    "    mask = df_test[\"month\"].isin(months)\n",
    "    if not np.any(mask):\n",
    "        season_preds[name] = None\n",
    "        continue\n",
    "    X_s   = df_test.loc[mask, features]\n",
    "    y_s   = df_test.loc[mask, \"xco2\"].values\n",
    "    yhat_s = best_model.predict(X_s)\n",
    "    season_preds[name] = (y_s, yhat_s)\n",
    "\n",
    "all_true = np.concatenate([v[0] for v in season_preds.values() if v is not None])\n",
    "all_pred = np.concatenate([v[1] for v in season_preds.values() if v is not None])\n",
    "vmin = np.nanmin([all_true.min(), all_pred.min()])\n",
    "vmax = np.nanmax([all_true.max(), all_pred.max()])\n",
    "pad  = 0.02 * (vmax - vmin)\n",
    "lims = (vmin - pad, vmax + pad)\n",
    "\n",
    "mpl.rcParams.update({\n",
    "    \"font.size\": 11,\n",
    "    \"axes.linewidth\": 1.0,\n",
    "    \"xtick.direction\": \"in\",\n",
    "    \"ytick.direction\": \"in\",\n",
    "    \"xtick.major.size\": 4,\n",
    "    \"ytick.major.size\": 4,\n",
    "})\n",
    "\n",
    "def panel(ax, y_true, y_pred, tag, title, rmse, mae, mb, r2,\n",
    "          gridsize=200, cmap=\"RdYlBu_r\"):\n",
    "    hb = ax.hexbin(\n",
    "        y_true, y_pred,\n",
    "        gridsize=gridsize, extent=[*lims, *lims], cmap=cmap,\n",
    "        mincnt=1, bins='log'\n",
    "    )\n",
    "    ax.plot(lims, lims, ls=\"--\", lw=1.2, color=\"k\")\n",
    "    ax.set_xlim(lims); ax.set_ylim(lims)\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    ax.set_xlabel(\"Observed XCO$_2$ (ppm)\")\n",
    "    ax.set_ylabel(\"Predicted XCO$_2$ (ppm)\")\n",
    "    ax.text(0.02, 0.98, f\"({tag})\", transform=ax.transAxes,\n",
    "            va=\"top\", ha=\"left\", fontsize=13, fontweight=\"bold\")\n",
    "    ax.text(0.40, 0.30,\n",
    "            f\"RMSE = {rmse:.2f} ppm\\nMAE = {mae:.2f} ppm\\nMB = {mb:+.2f} ppm\\n$R^2$ = {r2:.2f}\",\n",
    "            transform=ax.transAxes, va=\"top\", ha=\"left\",\n",
    "            bbox=dict(boxstyle=\"round,pad=0.25\", fc=\"white\", ec=\"0.6\", lw=0.8))\n",
    "    return hb\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(7.0, 6.5), sharex=True, sharey=True)\n",
    "for ax, (tag, (name, _)) in zip(axes.ravel(), zip(tags, seasons.items())):\n",
    "    pair = season_preds[name]\n",
    "    if pair is None:\n",
    "        ax.text(0.5, 0.5, f\"No data: {name}\", ha=\"center\", va=\"center\", transform=ax.transAxes)\n",
    "        ax.axis(\"off\")\n",
    "        continue\n",
    "\n",
    "    y_s, yhat_s = pair\n",
    "    rmse = np.sqrt(mean_squared_error(y_s, yhat_s))\n",
    "    mae  = mean_absolute_error(y_s, yhat_s)\n",
    "    mb   = np.mean(yhat_s - y_s)\n",
    "    r2   = r2_score(y_s, yhat_s)\n",
    "\n",
    "    panel(ax, y_s, yhat_s, tag, name, rmse, mae, mb, r2, gridsize=80, cmap=\"RdYlBu_r\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6aed24",
   "metadata": {},
   "source": [
    "### **2.4.5 Plot lattitude-belt scattering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16339beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = df_trainval.copy()\n",
    "required_cols = {\"lon\", \"lat\", \"y_true\", \"y_pred\"}\n",
    "X_test = data_df[features]\n",
    "y_test = data_df[\"xco2\"]\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "data_df[\"y_pred\"]= y_pred_test \n",
    "data_df[\"y_true\"]=data_df[\"xco2\"]\n",
    "\n",
    "missing = required_cols - set(data_df.columns)\n",
    "\n",
    "lon = data_df[\"lon\"].to_numpy()\n",
    "if np.nanmax(lon) > 180:\n",
    "    data_df = data_df.copy()\n",
    "    data_df[\"lon\"] = ((lon + 180) % 360) - 180\n",
    "\n",
    "def _clean_xy(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    m = np.isfinite(y_true) & np.isfinite(y_pred)\n",
    "    return y_true[m], y_pred[m]\n",
    "\n",
    "BIN_DEG = 20\n",
    "bins = np.arange(-90, 90 + BIN_DEG, BIN_DEG)   \n",
    "labels = [f\"[{bins[i]},{bins[i+1]})\" for i in range(len(bins)-1)]\n",
    "labels[-1] = labels[-1].replace(\")\", \"]\")\n",
    "\n",
    "lat_vals = data_df[\"lat\"].to_numpy()\n",
    "idx = np.digitize(lat_vals, bins, right=True) - 1  \n",
    "idx = np.clip(idx, 0, len(labels)-1)\n",
    "\n",
    "data_df = data_df.assign(\n",
    "    lat_band_idx = idx,\n",
    "    lat_band = pd.Categorical([labels[i] for i in idx],\n",
    "                              categories=labels, ordered=True)\n",
    ")\n",
    "\n",
    "rows = []\n",
    "for i, band in enumerate(labels):\n",
    "    sub = data_df[data_df[\"lat_band_idx\"] == i]\n",
    "    yt, yp = _clean_xy(sub[\"y_true\"].to_numpy(), sub[\"y_pred\"].to_numpy())\n",
    "    n = len(yt)\n",
    "    if n == 0:\n",
    "        rows.append({\n",
    "            \"lat_band\": band, \"n\": 0,\n",
    "            \"RMSE\": np.nan, \"MAE\": np.nan, \"MB\": np.nan, \"R2\": np.nan,\n",
    "            \"y_true_mean\": np.nan, \"y_pred_mean\": np.nan\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    rmse = float(np.sqrt(mean_squared_error(yt, yp)))\n",
    "    mae  = float(mean_absolute_error(yt, yp))\n",
    "    mb   = float(np.nanmean(yp - yt))\n",
    "    try:\n",
    "        r2 = float(r2_score(yt, yp))\n",
    "    except Exception:\n",
    "        r2 = np.nan\n",
    "\n",
    "    rows.append({\n",
    "        \"lat_band\": band, \"n\": n,\n",
    "        \"RMSE\": rmse, \"MAE\": mae, \"MB\": mb, \"R2\": r2,\n",
    "        \"y_true_mean\": float(np.nanmean(yt)), \"y_pred_mean\": float(np.nanmean(yp))\n",
    "    })\n",
    "\n",
    "metrics_by_latband = pd.DataFrame(rows).set_index(\"lat_band\")\n",
    "\n",
    "yt_all, yp_all = _clean_xy(data_df[\"y_true\"].to_numpy(), data_df[\"y_pred\"].to_numpy())\n",
    "if len(yt_all) > 0:\n",
    "    overall = pd.DataFrame({\n",
    "        \"n\": [len(yt_all)],\n",
    "        \"RMSE\": [float(np.sqrt(mean_squared_error(yt_all, yp_all)))],\n",
    "        \"MAE\": [float(mean_absolute_error(yt_all, yp_all))],\n",
    "        \"MB\": [float(np.nanmean(yp_all - yt_all))],\n",
    "        \"R2\": [float(r2_score(yt_all, yp_all)) if np.var(yt_all) > 0 else np.nan],\n",
    "        \"y_true_mean\": [float(np.nanmean(yt_all))],\n",
    "        \"y_pred_mean\": [float(np.nanmean(yp_all))]\n",
    "    }, index=[\"All\"])\n",
    "    metrics_by_latband = pd.concat([metrics_by_latband, overall], axis=0)\n",
    "\n",
    "order = [\"n\", \"RMSE\", \"MAE\", \"MB\", \"R2\", \"y_true_mean\", \"y_pred_mean\"]\n",
    "metrics_by_latband = metrics_by_latband[order]\n",
    "metrics_by_latband[[\"RMSE\",\"MAE\",\"MB\",\"R2\",\"y_true_mean\",\"y_pred_mean\"]] = \\\n",
    "    metrics_by_latband[[\"RMSE\",\"MAE\",\"MB\",\"R2\",\"y_true_mean\",\"y_pred_mean\"]].round(3)\n",
    "\n",
    "print(\"every 10° latitude belt performance：\")\n",
    "metrics_by_latband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a12278",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = df_test.copy()\n",
    "required_cols = {\"lon\", \"lat\", \"y_true\", \"y_pred\"}\n",
    "X_test = data_df[features]\n",
    "y_test = data_df[\"xco2\"]\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "data_df[\"y_pred\"]= y_pred_test \n",
    "data_df[\"y_true\"]=data_df[\"xco2\"]\n",
    "\n",
    "missing = required_cols - set(data_df.columns)\n",
    "\n",
    "lon = data_df[\"lon\"].to_numpy()\n",
    "if np.nanmax(lon) > 180:\n",
    "    data_df = data_df.copy()\n",
    "    data_df[\"lon\"] = ((lon + 180) % 360) - 180\n",
    "\n",
    "def _clean_xy(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    m = np.isfinite(y_true) & np.isfinite(y_pred)\n",
    "    return y_true[m], y_pred[m]\n",
    "\n",
    "BIN_DEG = 20\n",
    "bins = np.arange(-90, 90 + BIN_DEG, BIN_DEG)   \n",
    "labels = [f\"[{bins[i]},{bins[i+1]})\" for i in range(len(bins)-1)]\n",
    "labels[-1] = labels[-1].replace(\")\", \"]\")\n",
    "\n",
    "lat_vals = data_df[\"lat\"].to_numpy()\n",
    "idx = np.digitize(lat_vals, bins, right=True) - 1  \n",
    "idx = np.clip(idx, 0, len(labels)-1)\n",
    "\n",
    "data_df = data_df.assign(\n",
    "    lat_band_idx = idx,\n",
    "    lat_band = pd.Categorical([labels[i] for i in idx],\n",
    "                              categories=labels, ordered=True)\n",
    ")\n",
    "\n",
    "rows = []\n",
    "for i, band in enumerate(labels):\n",
    "    sub = data_df[data_df[\"lat_band_idx\"] == i]\n",
    "    yt, yp = _clean_xy(sub[\"y_true\"].to_numpy(), sub[\"y_pred\"].to_numpy())\n",
    "    n = len(yt)\n",
    "    if n == 0:\n",
    "        rows.append({\n",
    "            \"lat_band\": band, \"n\": 0,\n",
    "            \"RMSE\": np.nan, \"MAE\": np.nan, \"MB\": np.nan, \"R2\": np.nan,\n",
    "            \"y_true_mean\": np.nan, \"y_pred_mean\": np.nan\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    rmse = float(np.sqrt(mean_squared_error(yt, yp)))\n",
    "    mae  = float(mean_absolute_error(yt, yp))\n",
    "    mb   = float(np.nanmean(yp - yt))\n",
    "    try:\n",
    "        r2 = float(r2_score(yt, yp))\n",
    "    except Exception:\n",
    "        r2 = np.nan\n",
    "\n",
    "    rows.append({\n",
    "        \"lat_band\": band, \"n\": n,\n",
    "        \"RMSE\": rmse, \"MAE\": mae, \"MB\": mb, \"R2\": r2,\n",
    "        \"y_true_mean\": float(np.nanmean(yt)), \"y_pred_mean\": float(np.nanmean(yp))\n",
    "    })\n",
    "\n",
    "metrics_by_latband = pd.DataFrame(rows).set_index(\"lat_band\")\n",
    "\n",
    "yt_all, yp_all = _clean_xy(data_df[\"y_true\"].to_numpy(), data_df[\"y_pred\"].to_numpy())\n",
    "if len(yt_all) > 0:\n",
    "    overall = pd.DataFrame({\n",
    "        \"n\": [len(yt_all)],\n",
    "        \"RMSE\": [float(np.sqrt(mean_squared_error(yt_all, yp_all)))],\n",
    "        \"MAE\": [float(mean_absolute_error(yt_all, yp_all))],\n",
    "        \"MB\": [float(np.nanmean(yp_all - yt_all))],\n",
    "        \"R2\": [float(r2_score(yt_all, yp_all)) if np.var(yt_all) > 0 else np.nan],\n",
    "        \"y_true_mean\": [float(np.nanmean(yt_all))],\n",
    "        \"y_pred_mean\": [float(np.nanmean(yp_all))]\n",
    "    }, index=[\"All\"])\n",
    "    metrics_by_latband = pd.concat([metrics_by_latband, overall], axis=0)\n",
    "\n",
    "order = [\"n\", \"RMSE\", \"MAE\", \"MB\", \"R2\", \"y_true_mean\", \"y_pred_mean\"]\n",
    "metrics_by_latband = metrics_by_latband[order]\n",
    "metrics_by_latband[[\"RMSE\",\"MAE\",\"MB\",\"R2\",\"y_true_mean\",\"y_pred_mean\"]] = \\\n",
    "    metrics_by_latband[[\"RMSE\",\"MAE\",\"MB\",\"R2\",\"y_true_mean\",\"y_pred_mean\"]].round(3)\n",
    "\n",
    "print(\"every 10° latitude belt performance：\")\n",
    "metrics_by_latband"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae87d93e-5910-4312-a1ea-4b173ba93313",
   "metadata": {},
   "source": [
    "# **3. SHAP Plotting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13df2b1f-5e72-4832-b8ec-c2fa26b9da10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_sample = X.sample(n=10000, random_state=42)\n",
    "\n",
    "explainer = shap.Explainer(best_model)\n",
    "\n",
    "shap_values = explainer(X_sample) \n",
    "\n",
    "vals = np.abs(shap_values.values) \n",
    "mean_abs = vals.mean(axis=0) \n",
    "total = mean_abs.sum()\n",
    "pct = 100.0 * mean_abs / total \n",
    "\n",
    "imp_df = pd.DataFrame({\n",
    "    \"feature\": X_sample.columns,\n",
    "    \"mean_abs_shap\": mean_abs,\n",
    "    \"percent\": pct\n",
    "}).sort_values(\"percent\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e86670",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams.update({\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.sans-serif\": [\"Arial\", \"Helvetica\", \"DejaVu Sans\"],\n",
    "    \"font.size\": 10,\n",
    "    \"axes.linewidth\": 0.8,\n",
    "    \"axes.labelsize\": 10,\n",
    "    \"axes.titlesize\": 10,\n",
    "    \"xtick.direction\": \"in\",\n",
    "    \"ytick.direction\": \"in\",\n",
    "    \"xtick.labelsize\": 10,\n",
    "    \"ytick.labelsize\": 10,    \n",
    "    \"xtick.major.size\": 4,\n",
    "    \"ytick.major.size\": 4,\n",
    "    \"legend.frameon\": False,\n",
    "    \"figure.titlesize\": 10,\n",
    "})\n",
    "\n",
    "colmap = {\n",
    "    \"t2m\": \"T2\",\n",
    "    \"d2m\": \"DP2\",\n",
    "    \"u10\": \"U10\",\n",
    "    \"v10\": \"V10\",\n",
    "    \"msl\": \"MSL\",\n",
    "    \"sp\":  \"Psfc\",\n",
    "    \"skt\": \"TS\",\n",
    "    \"tp\": \"Prec\",\n",
    "    \"e\": \"E\",\n",
    "    \"ssr\": \"SSR\",\n",
    "    \"str\": \"STR\",\n",
    "    \"tcw\": \"TCW\",\n",
    "    \"blh\": \"BLH\",\n",
    "    \"NO2\": \"NO2\",\n",
    "    \"is_weekend\": \"WE\",\n",
    "    \"population\": \"POP\",\n",
    "    \"elevation\": \"ELE\",\n",
    "    \"aspect\": \"ASP\",\n",
    "    \"ndvi\": \"NDVI\",\n",
    "    \"gpp\": \"GPP\",\n",
    "    \"lai\": \"LAI\",\n",
    "    \"ntl\": \"NTL\",\n",
    "    \"evi\": \"EVI\",\n",
    "    \"slope\": \"SLO\",\n",
    "    \"odiac\": \"FFE\",\n",
    "    \"CO2_fire\": \"BBE\",\n",
    "    \"geo_x\": \"geo_x\",\n",
    "    \"geo_y\": \"geo_y\",\n",
    "    \"geo_z\": \"geo_z\",\n",
    "    \"month_sin\": \"mon_sin\",\n",
    "    \"month_cos\": \"mon_cos\",\n",
    "}\n",
    "\n",
    "X_sample = X.sample(n=5000, random_state=42)  # 或直接用 X\n",
    "explainer = shap.TreeExplainer(best_model, feature_perturbation=\"interventional\", model_output=\"raw\")\n",
    "shap_values = explainer(X_sample)\n",
    "X_plot = X_sample.rename(columns=colmap, errors=\"ignore\")\n",
    "\n",
    "shap.summary_plot(\n",
    "    shap_values, X_plot, plot_type=\"dot\", feature_names=list(X_plot.columns),\n",
    "    cmap=mpl.colormaps['RdBu_r'], color_bar_label=\"Feature value\", max_display=15,\n",
    "    show=False\n",
    ")\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(7, 7)\n",
    "ax = plt.gca()\n",
    "for spine in [\"top\", \"right\"]:\n",
    "    ax.spines[spine].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d966209",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams.update({\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.sans-serif\": [\"Arial\", \"Helvetica\", \"DejaVu Sans\"],\n",
    "    \"font.size\": 14,\n",
    "    \"axes.linewidth\": 0.8,\n",
    "    \"axes.labelsize\": 8,\n",
    "    \"axes.titlesize\": 8,\n",
    "    \"xtick.direction\": \"in\",\n",
    "    \"ytick.direction\": \"in\",\n",
    "    \"xtick.labelsize\": 8,\n",
    "    \"ytick.labelsize\": 8,    \n",
    "    \"xtick.major.size\": 4,\n",
    "    \"ytick.major.size\": 4,\n",
    "    \"legend.frameon\": False,\n",
    "})\n",
    "\n",
    "X_sample = X.sample(n=500, random_state=42) \n",
    "shap_values_numpy = explainer.shap_values(X_sample)\n",
    "fig, ax1 = plt.subplots(figsize=(10, 8), dpi=300)\n",
    "X_plot = X_sample.rename(columns=colmap, errors=\"ignore\")\n",
    "\n",
    "shap.summary_plot(\n",
    "    shap_values_numpy, X_plot, plot_type=\"dot\", feature_names=list(X_plot.columns),\n",
    "    cmap=mpl.colormaps['RdBu_r'], color_bar_label=\"Feature value\", max_display=15,\n",
    "    show=False\n",
    ")\n",
    "\n",
    "cbar_ax = None\n",
    "for ax in fig.axes:\n",
    "    if ax.get_ylabel() == \"Feature value\" or ax.get_xlabel() == \"Feature value\":\n",
    "        cbar_ax = ax\n",
    "        break\n",
    "\n",
    "cbar_ax.set_ylabel(\"Feature value\", fontsize=14)\n",
    "\n",
    "\n",
    "plt.gca().set_position([0.5, 0.5, 0.65, 0.65])\n",
    "ax1 = plt.gca()\n",
    "\n",
    "for coll in ax1.collections:\n",
    "    if isinstance(coll, mcoll.PathCollection):\n",
    "        sizes = coll.get_sizes()\n",
    "        coll.set_sizes(sizes * 0.2)\n",
    "\n",
    "ax2 = ax1.twiny()\n",
    "\n",
    "shap.summary_plot(shap_values_numpy, X_plot, plot_type=\"bar\", show=False, max_display=15, color=\"#BDBDBD\")\n",
    "\n",
    "plt.gca().set_position([0.5, 0.5, 0.65, 0.65])\n",
    "ax1.set_zorder(2)\n",
    "ax1.patch.set_alpha(0) \n",
    "ax2.set_zorder(1)\n",
    "bars = ax2.patches \n",
    "for bar in bars:\n",
    "\n",
    "    ax1.set_xlabel('Shapley Value Contribution (Bee Swarm)', fontsize=14)\n",
    "    ax2.set_xlabel('Mean Shapley Value (Feature Importance)', fontsize=14)\n",
    "    ax2.xaxis.set_label_position('top') \n",
    "    ax2.xaxis.tick_top() \n",
    "    ax1.set_ylabel('Features', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216c500d",
   "metadata": {},
   "source": [
    "# **4. Learning Curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05584f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_trainval\n",
    "df_val   = df_test\n",
    "\n",
    "dtrain = xgb.DMatrix(df_train[features], label=df_train[\"xco2\"])\n",
    "dval   = xgb.DMatrix(df_val[features],   label=df_val[\"xco2\"])\n",
    "\n",
    "scoring = {\n",
    "    \"RMSE\": \"neg_root_mean_squared_error\",\n",
    "    \"R2\":   \"r2\"\n",
    "}\n",
    "\n",
    "splits = list(gkf.split(X, y, groups=groups))\n",
    "\n",
    "params = {k: (v[0] if isinstance(v, (list, tuple, np.ndarray)) else v)\n",
    "          for k, v in param_grid.items()}\n",
    "params.update({\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"tree_method\": \"hist\",\n",
    "})\n",
    "\n",
    "evals_result = {}\n",
    "bst = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=100,\n",
    "    evals=[(dtrain, \"train\"), (dval, \"validation\")],\n",
    "    early_stopping_rounds=50,\n",
    "    evals_result=evals_result,\n",
    "    verbose_eval=True\n",
    ")\n",
    "\n",
    "train_rmse = evals_result[\"train\"][\"rmse\"]\n",
    "val_rmse   = evals_result[\"validation\"][\"rmse\"]\n",
    "iters      = list(range(len(train_rmse)))\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(iters, train_nmse := train_rmse, label=\"Train RMSE\", lw=2)\n",
    "plt.plot(iters, val_rmse,        label=\"Val   RMSE\", lw=2)\n",
    "plt.axvline(bst.best_iteration, linestyle=\"--\", color=\"gray\",\n",
    "            label=f\"Early Stop @ {bst.best_iteration}\")\n",
    "plt.xlabel(\"Boosting Round\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"Learning Curve (Block-based Train/Val Split)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
